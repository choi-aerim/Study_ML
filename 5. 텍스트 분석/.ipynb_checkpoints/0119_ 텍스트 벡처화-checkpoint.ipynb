{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d277555d",
   "metadata": {},
   "source": [
    "# Bag of Word(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0297815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8689ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70d99d",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5c398d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"누구나 한번쯤은 사랑에 웃고\", \n",
    "        \"누구나 한번쯤은 사랑에 울고\",\n",
    "        \"그것이 바로 사랑 사랑 사랑이야\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64d0db60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 0 0 1 1]\n",
      " [0 1 0 0 1 0 1 0 1]\n",
      " [1 0 1 2 0 1 0 0 0]]\n",
      "[('그것이', 0), ('누구나', 1), ('바로', 2), ('사랑', 3), ('사랑에', 4), ('사랑이야', 5), ('울고', 6), ('웃고', 7), ('한번쯤은', 8)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "# 피처들의 벡터화된 값만 확인\n",
    "temp_vec = cv.fit_transform(text)\n",
    "print(temp_vec.toarray())\n",
    "\n",
    "# 피처 컬럼명을 나타내는 값 확인\n",
    "temp_vec_dict = cv.vocabulary_.items()\n",
    "print(sorted(temp_vec_dict))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bb30516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 0 0 0 1 0 1 0 0 1 1 1]\n",
      " [0 0 1 1 0 0 0 0 0 1 1 0 0 1 0 1 1]\n",
      " [1 1 0 0 1 1 2 1 1 0 0 0 1 0 0 0 0]]\n",
      "[('그것이', 0), ('그것이 바로', 1), ('누구나', 2), ('누구나 한번쯤은', 3), ('바로', 4), ('바로 사랑', 5), ('사랑', 6), ('사랑 사랑', 7), ('사랑 사랑이야', 8), ('사랑에', 9), ('사랑에 울고', 10), ('사랑에 웃고', 11), ('사랑이야', 12), ('울고', 13), ('웃고', 14), ('한번쯤은', 15), ('한번쯤은 사랑에', 16)]\n"
     ]
    }
   ],
   "source": [
    "cv2 = CountVectorizer(ngram_range = (1, 2))\n",
    "\n",
    "# 피처들의 벡터화된 값만 확인\n",
    "temp_vec = cv2.fit_transform(text)\n",
    "print(temp_vec.toarray())\n",
    "\n",
    "# 피처 컬럼명을 나타내는 값 확인\n",
    "temp_vec_dict = cv2.vocabulary_.items()\n",
    "print(sorted(temp_vec_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b72e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 1 1]\n",
      " [1 0 1 0 1 0 1]\n",
      " [0 2 0 1 0 0 0]]\n",
      "[('누구나', 0), ('사랑', 1), ('사랑에', 2), ('사랑이야', 3), ('울고', 4), ('웃고', 5), ('한번쯤은', 6)]\n"
     ]
    }
   ],
   "source": [
    "cv3 = CountVectorizer(stop_words = ['그것이', '바로'])\n",
    "\n",
    "# 피처들의 벡터화된 값만 확인\n",
    "temp_vec = cv3.fit_transform(text)\n",
    "print(temp_vec.toarray())\n",
    "\n",
    "# 피처 컬럼명을 나타내는 값 확인\n",
    "temp_vec_dict = cv3.vocabulary_.items()\n",
    "print(sorted(temp_vec_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc66083",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b727e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.46 0.   0.   0.46 0.   0.   0.6  0.46]\n",
      " [0.   0.46 0.   0.   0.46 0.   0.6  0.   0.46]\n",
      " [0.38 0.   0.38 0.76 0.   0.38 0.   0.   0.  ]]\n",
      "[('그것이', 0), ('누구나', 1), ('바로', 2), ('사랑', 3), ('사랑에', 4), ('사랑이야', 5), ('울고', 6), ('웃고', 7), ('한번쯤은', 8)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# 피처들의 벡터화된 값만 확인\n",
    "temp_vec = tfidf.fit_transform(text)\n",
    "print(np.round(temp_vec.toarray(), 2) ) # 가중치, 페널티를 고려해서 점수가 나옴\n",
    "\n",
    "# 피처 컬럼명을 나타내는 값 확인\n",
    "temp_vec_dict = tfidf.vocabulary_.items()\n",
    "print(sorted(temp_vec_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5f30b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58 0.58 0.58]\n",
      " [0.58 0.58 0.58]\n",
      " [0.   0.   0.  ]]\n",
      "[('누구나', 0), ('사랑에', 1), ('한번쯤은', 2)]\n"
     ]
    }
   ],
   "source": [
    "tfidf2 = TfidfVectorizer(min_df = 2)\n",
    "\n",
    "# 피처들의 벡터화된 값만 확인\n",
    "temp_vec = tfidf2.fit_transform(text)\n",
    "print(np.round(temp_vec.toarray(), 2) ) # 가중치, 페널티를 고려해서 점수가 나옴\n",
    "\n",
    "# 피처 컬럼명을 나타내는 값 확인\n",
    "temp_vec_dict = tfidf2.vocabulary_.items()\n",
    "print(sorted(temp_vec_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb171f8",
   "metadata": {},
   "source": [
    "#### 정규표현식 활용해서 정규화 후 피처벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5347336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def ko_tokenize(text):\n",
    "    text = re.sub('(\\w+)[은에를]', '\\g<1>', text)\n",
    "    text = re.sub('[이야]', '', text)\n",
    "    text = re.sub('(\\w+)[고]', '\\g<1>다', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e291311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['누구나 한번쯤은 사랑에 웃고', '누구나 한번쯤은 사랑에 울고', '그것이 바로 사랑 사랑 사랑이야']\n",
      "['누구나 한번쯤 사랑 웃다', '누구나 한번쯤 사랑 울다', '그것 바로 사랑 사랑 사랑']\n"
     ]
    }
   ],
   "source": [
    "text_x = text.copy()\n",
    "print(text_x)\n",
    "\n",
    "texts = [ko_tokenize(t) for t in text_x]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "beef6f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.48 0.   0.37 0.   0.63 0.48]\n",
      " [0.   0.48 0.   0.37 0.63 0.   0.48]\n",
      " [0.44 0.   0.44 0.78 0.   0.   0.  ]]\n",
      "[('그것', 0), ('누구나', 1), ('바로', 2), ('사랑', 3), ('울다', 4), ('웃다', 5), ('한번쯤', 6)]\n"
     ]
    }
   ],
   "source": [
    "tfidf3 = TfidfVectorizer()\n",
    "\n",
    "# 피처들의 벡터화된 값만 확인\n",
    "temp_vec = tfidf3.fit_transform(texts)\n",
    "print(np.round(temp_vec.toarray(), 2) ) # 가중치, 페널티를 고려해서 점수가 나옴\n",
    "\n",
    "# 피처 컬럼명을 나타내는 값 확인\n",
    "temp_vec_dict = tfidf3.vocabulary_.items()\n",
    "print(sorted(temp_vec_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f717d",
   "metadata": {},
   "source": [
    "## 희소행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05779219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361946b3",
   "metadata": {},
   "source": [
    "### COO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9155fc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 2)\t2\n",
      "  (1, 1)\t4\n",
      "[[1 0 2]\n",
      " [0 4 0]]\n"
     ]
    }
   ],
   "source": [
    "# 피처벡터화된 원본 배열 예시\n",
    "arr = np.array([[1, 0, 2], [0, 4, 0]])\n",
    "\n",
    "# 0이 아닌 데이터만 배열화\n",
    "data = np.array([1, 2, 4])\n",
    "\n",
    "# 행/열 인덱스화 \n",
    "row_idx = np.array([0, 0, 1])\n",
    "col_idx = np.array([0, 2, 1])\n",
    "\n",
    "\n",
    "sparse_coo = sparse.coo_matrix((data, (row_idx, col_idx)))\n",
    "print(sparse_coo)\n",
    "\n",
    "print(sparse_coo.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee26ef",
   "metadata": {},
   "source": [
    "### CSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4bb09d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 5)\t5\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t4\n",
      "  (1, 3)\t3\n",
      "  (1, 4)\t2\n",
      "  (1, 5)\t5\n",
      "  (2, 1)\t6\n",
      "  (2, 3)\t3\n",
      "  (3, 0)\t2\n",
      "  (4, 3)\t7\n",
      "  (4, 5)\t8\n",
      "  (5, 0)\t1\n",
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 피처벡터화된 원본 배열 예시\n",
    "arr = np.array([[0,0,1,0,0,5], [1,4,0,3,2,5], [0,6,0,3,0,0], [2,0,0,0,0,0], [0,0,0,7,0,8], [1,0,0,0,0,0]])\n",
    "\n",
    "# 0이 아닌 데이터만 배열화\n",
    "data = np.array([1, 5, 1, 4, 3, 2, 5, 6, 3, 2, 7, 8, 1])\n",
    "\n",
    "# 행/열 인덱스화 \n",
    "row_idx = np.array([0, 0, 1, 1, 1, 1, 1, 2, 2, 3, 4, 4, 5])\n",
    "col_idx = np.array([2, 5, 0, 1, 3, 4, 5, 1, 3, 0, 3, 5, 0])\n",
    "# 행 인덱스의 인덱스화\n",
    "row_idx_idx = np.array([0, 2, 7, 9, 10, 12, 13])\n",
    "\n",
    " \n",
    "sparse_csr = sparse.csr_matrix((data, col_idx, row_idx_idx))\n",
    "print(sparse_csr)\n",
    "\n",
    "print(sparse_csr.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a48df1",
   "metadata": {},
   "source": [
    "### 배열과 희소행렬 변환 방식(coo, csr)을 입력하면 반환해주는 사용자 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a986334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0 5]\n",
      " [1 4 0 3 2 5]\n",
      " [0 6 0 3 0 0]\n",
      " [2 0 0 0 0 0]\n",
      " [0 0 0 7 0 8]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEW\\AppData\\Local\\Temp\\ipykernel_7872\\2136723650.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  row_idx_idx = np.array([np.where(row_idx == idx)[0] for idx in set(row_idx)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sparse_transform(arr, method = 'coo', return_arr = False):\n",
    "    # 0이 아닌 숫자만 채운 배열 만들기\n",
    "    data = arr[arr != 0]\n",
    "    \n",
    "    # 행/열 인덱스 배열 만들기\n",
    "    row_idx = np.where(arr != 0)[0]\n",
    "    col_idx = np.where(arr != 0)[1]\n",
    "    \n",
    "    # 행 인덱스의 인덱스 배열 만들기\n",
    "    row_idx_idx = np.array([np.where(row_idx == idx)[0] for idx in set(row_idx)])\n",
    "    \n",
    "    # coo/csr 변환\n",
    "    if method == 'coo':\n",
    "        sparse_coo = sparse.coo_matrix((data, (row_idx, col_idx)))\n",
    "        if return_arr:\n",
    "            return sparse_coo.toarray()\n",
    "        else:\n",
    "            print(sparse_coo.toarray())\n",
    "    elif method == 'csr':\n",
    "        sparse_csr = sparse.csr_matrix((data, col_idx, row_idx_idx))\n",
    "        if return_arr:\n",
    "            return sparse_csr.toarray()\n",
    "        else:\n",
    "            print(sparse_csr.toarray())\n",
    "            \n",
    "sparse_transform(arr, method = 'coo', return_arr = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b7d08",
   "metadata": {},
   "source": [
    "# 실습: 뉴스그룹 분류 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f1d17",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53489b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d99c76dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data = fetch_20newsgroups(subset = 'all', random_state = 156)\n",
    "news_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1aab57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 value:  0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n",
      "레이블 이름:  ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# 레이블 데이터들 탐색\n",
    "\n",
    "print('레이블 value: ', pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('레이블 이름: ', news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c21fe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c191a0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "What I did NOT get with my drive (CD300i) is the System Install CD you\n",
      "listed as #1.  Any ideas about how I can get one?  I bought my IIvx 8/120\n",
      "from Direct Express in Chicago (no complaints at all -- good price & good\n",
      "service).\n",
      "\n",
      "BTW, I've heard that the System Install CD can be used to boot the mac;\n",
      "however, my drive will NOT accept a CD caddy is the machine is off.  How can\n",
      "you boot with it then?\n",
      "\n",
      "--Dave\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터 로드\n",
    "\n",
    "train_news = fetch_20newsgroups(subset = 'train', remove = ('headers', 'footers', 'quotes'),\n",
    "                                random_state = 156)\n",
    "\n",
    "print(train_news.data[0])\n",
    "print(train_news.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4a374491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_news.data\n",
    "y_train = train_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da3e19c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tech support line for GCC is 1-800-231-1570.\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터 로드\n",
    "\n",
    "\n",
    "test_news = fetch_20newsgroups(subset = 'test', remove = ('headers', 'footers', 'quotes'),\n",
    "                                random_state = 156)\n",
    "\n",
    "print(test_news.data[0])\n",
    "print(test_news.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e514c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_news.data\n",
    "y_test = test_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1dd5eac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 11314\n",
      "7532 7532\n"
     ]
    }
   ],
   "source": [
    "# 데이터 크기 확인\n",
    "\n",
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30d693",
   "metadata": {},
   "source": [
    "## 1.  CountVectorizer 피처벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "081d912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f360e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer()\n",
    "\n",
    "# 학습용 데이터 학습\n",
    "cnt_vect.fit(X_train)\n",
    "\n",
    "# 학습용 데이터 피처벡터화\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "\n",
    "\n",
    "print(X_train_cnt_vect.toarray())\n",
    "print(X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d543ca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000', '000000', '00000000', '0000000004', '00000000b', '00000001', '00000001b', '00000010', '00000010b', '00000011', '00000011b', '00000074', '00000093', '000000e5', '00000100', '00000100b', '00000101']\n"
     ]
    }
   ],
   "source": [
    "# 피처 names 확인\n",
    "\n",
    "print(sorted(cnt_vect.vocabulary_.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cc7ddaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터 피처벡터화\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "\n",
    "print(X_test_cnt_vect.toarray())\n",
    "print(X_test_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rint(sorted(cnt_vect.vocabulary_.keys())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29992f",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀 모델링 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "30b0c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7b2cc",
   "metadata": {},
   "source": [
    "#### solver = 'liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f484c043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6166\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "# 학습\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)\n",
    "\n",
    "# 예측\n",
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'정확도: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1f183b",
   "metadata": {},
   "source": [
    "#### solver = 'lbfgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0b66256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6166\n"
     ]
    }
   ],
   "source": [
    "lr_clf2 = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "# 학습\n",
    "lr_clf2.fit(X_train_cnt_vect, y_train)\n",
    "\n",
    "# 예측\n",
    "pred2 = lr_clf2.predict(X_test_cnt_vect)\n",
    "\n",
    "# 평가\n",
    "accuracy2 = accuracy_score(y_test, pred2)\n",
    "print(f'정확도: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354733bd",
   "metadata": {},
   "source": [
    "- 크게 차이 없음.. 분명히 다중분류와 큰 데이터셋에는 lbfgs가 성능이 좋다고 알려져있었는데,, ㅋㅋ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b4108",
   "metadata": {},
   "source": [
    "## 2.  TF-IDFVectorizer 피처벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "df35e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f2c9c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# 학습\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "# 학습용 데이터 피처벡터화\n",
    "X_train_tf_vect = tfidf_vect.transform(X_train)\n",
    "\n",
    "print(X_train_tf_vect.toarray())\n",
    "print(X_train_tf_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f918b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(7532, 101631)\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터 피처벡터화\n",
    "X_test_tf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "print(X_test_tf_vect.toarray())\n",
    "print(X_test_tf_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb9235",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀 모델링 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3285d25e",
   "metadata": {},
   "source": [
    "#### solver = 'liblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "227cd6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6775\n"
     ]
    }
   ],
   "source": [
    "lr_clf3 = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "# 학습\n",
    "lr_clf3.fit(X_train_tf_vect, y_train)\n",
    "\n",
    "# 예측\n",
    "pred3 = lr_clf3.predict(X_test_tf_vect)\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(y_test, pred3)\n",
    "print(f'정확도: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7523488",
   "metadata": {},
   "source": [
    "#### solver = 'lbfgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "34b3a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6775\n"
     ]
    }
   ],
   "source": [
    "lr_clf4 = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "# 학습\n",
    "lr_clf4.fit(X_train_tf_vect, y_train)\n",
    "\n",
    "# 예측\n",
    "pred4 = lr_clf4.predict(X_test_tf_vect)\n",
    "\n",
    "# 평가\n",
    "accuracy4 = accuracy_score(y_test, pred4)\n",
    "print(f'정확도: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754811a5",
   "metadata": {},
   "source": [
    "### 결론\n",
    "- count 기반보다 tf-idf 기반으로 피처벡터화 후 모델 적용한 것이 성능이 좋게 나타남\n",
    "- 머신러닝 성능을 좋게 하는 방법 두가지는,\n",
    "    - 최신 ml알고리즘 사용\n",
    "    - 최상의 피처 전처리 수행\n",
    "- 분류모델링 하이퍼파라미터 튜닝해보겠음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c58e9",
   "metadata": {},
   "source": [
    "## 로지스틱회귀 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc3d3f",
   "metadata": {},
   "source": [
    "#### 임의의 하이퍼파라미터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e9a1db19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 943453)\n",
      "(7532, 943453)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words = 'english',\n",
    "                             max_df = 300,\n",
    "                             ngram_range = (1, 2))\n",
    "\n",
    "# 학습\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "# 학습용 데이터 피처벡터화\n",
    "X_train_tf_vect = tfidf_vect.transform(X_train)\n",
    "print(X_train_tf_vect.shape)\n",
    "\n",
    "# 테스트용 데이터 피처벡터화\n",
    "X_test_tf_vect = tfidf_vect.transform(X_test)\n",
    "print(X_test_tf_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a5a0f",
   "metadata": {},
   "source": [
    "#### 로지스틱 회귀모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "230576d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6901\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "# 학습\n",
    "lr_clf.fit(X_train_tf_vect, y_train)\n",
    "\n",
    "# 예측\n",
    "pred_tf = lr_clf.predict(X_test_tf_vect)\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(y_test, pred_tf)\n",
    "print(f'정확도: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42f801",
   "metadata": {},
   "source": [
    "#### GridSearchCV를 활용한 로지스틱 회귀 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fd0835eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터: {'C': 10}\n",
      "정확도: 0.7039298990971854\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'C': [ 0.01, 0.1, 1, 5, 10]}\n",
    "\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf,\n",
    "                        param_grid = params, \n",
    "                        cv = 3,\n",
    "                        scoring = 'accuracy',\n",
    "                        verbose = 1)\n",
    "\n",
    "# 학습\n",
    "grid_clf.fit(X_train_tf_vect, y_train)\n",
    "\n",
    "# 최적 파라미터 추출\n",
    "print(f'최적의 파라미터: {grid_clf.best_params_}')\n",
    "\n",
    "# 최적 파라미터로 예측\n",
    "pred = grid_clf.predict(X_test_tf_vect)\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'정확도: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fca7aeb",
   "metadata": {},
   "source": [
    "### 결론\n",
    "- 로지스틱 분류회귀 하이퍼파라미터 튜닝하니까 뭐~ 0.01정도 올랐다\n",
    "- 분류 학습 말고, 피처벡터화 하이퍼파라미터 튜닝은 안되는지?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353014c",
   "metadata": {},
   "source": [
    "## 파이프라인을 활용한 알고리즘 설계\n",
    "- <b>파이프라인</b>:\n",
    "    - 피처 벡터화와 ML 알고리즘 학습/예측을 위한 코드 작성을 한 번에 할 수 있음\n",
    "    - 머신러닝에서 Pipeline이란 데이터의 가공, 변환 등의 전처리와 알고리즘을 통일된 API 기반에서 처리할 수 있어 더 직관적인 코드를 짤 수 있음\n",
    "    - 또한, 대용량의 피처 벡터화 결과를 별도의 데이터로 저장하지 않고 스트림 기반에서 바로 ML알고리즘의 데이터로 입력할 수 있기 때문에 수행 시간을 절약할 수 있음\n",
    "    - 피처 벡터화 뿐 아니라 모든 데이터 전처리 작업(스케일링, 벡터 정규화, pca 등)과 Estimator(분류, 회귀)를 결합할 수 있음\n",
    "    - 그리고 객체별 별도의 fit(), transform(), predict()등의 함수가 필요없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "15c44075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "424da236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 설계\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words = 'english',\n",
    "                                   ngram_range = (1,2),\n",
    "                                   max_df = 300)),\n",
    "    ('lr_clf', LogisticRegression(solver = 'liblinear',\n",
    "                                  C = 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1715f086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7039\n"
     ]
    }
   ],
   "source": [
    "# 학습용 데이터 적용  \n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 적용\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'정확도: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35390f13",
   "metadata": {},
   "source": [
    "### 파이프라인에 GridSearchCV 적용하여 최적의 하이퍼파라미터 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c4e18df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0db0ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words = 'english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b9ba7ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'tfidf_vect', 'lr_clf', 'tfidf_vect__analyzer', 'tfidf_vect__binary', 'tfidf_vect__decode_error', 'tfidf_vect__dtype', 'tfidf_vect__encoding', 'tfidf_vect__input', 'tfidf_vect__lowercase', 'tfidf_vect__max_df', 'tfidf_vect__max_features', 'tfidf_vect__min_df', 'tfidf_vect__ngram_range', 'tfidf_vect__norm', 'tfidf_vect__preprocessor', 'tfidf_vect__smooth_idf', 'tfidf_vect__stop_words', 'tfidf_vect__strip_accents', 'tfidf_vect__sublinear_tf', 'tfidf_vect__token_pattern', 'tfidf_vect__tokenizer', 'tfidf_vect__use_idf', 'tfidf_vect__vocabulary', 'lr_clf__C', 'lr_clf__class_weight', 'lr_clf__dual', 'lr_clf__fit_intercept', 'lr_clf__intercept_scaling', 'lr_clf__l1_ratio', 'lr_clf__max_iter', 'lr_clf__multi_class', 'lr_clf__n_jobs', 'lr_clf__penalty', 'lr_clf__random_state', 'lr_clf__solver', 'lr_clf__tol', 'lr_clf__verbose', 'lr_clf__warm_start'])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0a0456ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 243 out of 243 | elapsed: 38.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 파라미터: {'lr_clf__C': 5, 'tfidf_vect__max_df': 500, 'tfidf_vect__min_df': 10, 'tfidf_vect__ngram_range': (1, 1)}\n",
      "최적 score: 0.7136287291931064\n",
      "정확도:  0.6691\n"
     ]
    }
   ],
   "source": [
    "params = {'tfidf_vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "          'tfidf_vect__max_df': [100, 300, 500],\n",
    "          'tfidf_vect__min_df': [10, 20, 50],\n",
    "          'lr_clf__C': [1, 5, 10]}\n",
    "\n",
    "grid_clf_pipe = GridSearchCV(pipeline, \n",
    "                             param_grid = params,\n",
    "                             cv = 3,\n",
    "                             scoring = 'accuracy',\n",
    "                             verbose = 1)\n",
    "\n",
    "# 학습\n",
    "grid_clf_pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터 \n",
    "print(f'최적 파라미터: {grid_clf_pipe.best_params_}')\n",
    "print(f'최적 score: {grid_clf_pipe.best_score_}')\n",
    "\n",
    "\n",
    "# 예측\n",
    "pred = grid_clf_pipe.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(f'정확도: {accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d386e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d0cbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcc8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
